slug: "kafka"
name: "Build your own Kafka"
short_name: "Kafka"
release_status: "beta"

description_md: |-
  Apache Kafka is a distributed event streaming platform often used for high-performance data pipelines. In this challenge, you'll build your own Kafka broker
  that's capable of serving basic requests.

  Along the way you'll learn about TCP servers, the Kafka wire protocol and more.

short_description_md: |-
  Learn about TCP servers, the Kafka wire protocol and more.

completion_percentage: 15

languages:
  - slug: "cpp"
  - slug: "csharp"
  - slug: "gleam"
  - slug: "go"
  - slug: "java"
  - slug: "javascript"
  - slug: "python"
  - slug: "rust"
  - slug: "typescript"
  - slug: "zig"

marketing:
  difficulty: medium
  sample_extension_idea_title: "On Disk Storage"
  sample_extension_idea_description: "A Kafka broker that can read and write to disk"
  testimonials:
    - author_name: "Ananthalakshmi Sankar"
      author_description: "Automation Engineer at Apple"
      author_avatar: "https://codecrafters.io/images/external/testimonials/oxta.jpeg"
      link: "https://github.com/anu294"
      text: "There are few sites I like as much that have a step by step guide. The real-time feedback is so good, it's creepy!"

    - author_name: "Patrick Burris"
      author_description: "Senior Software Developer, CenturyLink"
      author_avatar: "https://codecrafters.io/images/external/testimonials/patrick-burris.jpeg"
      link: "https://github.com/Jumballaya"
      text: |-
        I think the instant feedback right there in the git push is really cool.
        Didn't even know that was possible!

extensions:
  - slug: "concurrent-clients"
    name: "Concurrent Clients"
    description_markdown: |
      In this challenge extension you'll add support for serving multiple clients simultaneously.

      Along the way you'll learn about TCP connections, how to handle concurrency and more.

  - slug: "listing-partitions"
    name: "Listing Partitions"
    description_markdown: |
      In this challenge extension you'll add support for listing topic partitions by implementing the [DescribeTopicPartitions][describe-topic-partitions] API.

      Along the way you'll learn about how Kafka stores messages on disk, the `__cluster_metadata` topic and more.

      [describe-topic-partitions]: https://kafka.apache.org/protocol.html#The_Messages_DescribeTopicPartitions

  - slug: "consuming-messages"
    name: "Consuming Messages"
    description_markdown: |
      In this challenge extension you'll add support for consuming messages by implementing the [Fetch][fetch-api] API.

      Along the way you'll learn about how Kafka's Fetch API works, how Kafka stores messages on disk and more.

      [fetch-api]: https://kafka.apache.org/protocol.html#The_Messages_Fetch

stages:
  - slug: "vi6"
    name: "Bind to a port"
    difficulty: easy
    description_md: |-
      In this stage, you'll implement a TCP server that listens on port 9092.

      [TCP](https://en.wikipedia.org/wiki/Transmission_Control_Protocol) is the underlying protocol that Kafka brokers and clients use to communicate with each other.

      ### Tests

      The tester will execute your program like this:
      ```
      $ ./your_program.sh
      ```

      It'll then try to connect to your TCP server on port 9092. If the connection succeeds, you'll pass this stage.

      ### Notes

      - If you already have a Kafka broker running on port 9092 and you run your program, you'll get a "port already in use" error. To fix this, terminate the existing Kafka broker and run your program again.
      - 9092 is the default port that Kafka uses.
    marketing_md: |-
      In this stage, you'll start a TCP server on port 9092, which is the
      default port that Kafka uses.

  - slug: "nv3"
    name: "Send Correlation ID"
    difficulty: easy
    description_md: |-
      In this stage, you'll send a response with a correlation ID.

      ### Response message

      Kafka brokers communicate with clients through the [Kafka wire protocol](https://kafka.apache.org/protocol.html). The protocol uses a request-response model, where the client sends a request message and the broker replies with a response message.

      A Kafka response message has three parts:
      1. `message_size`
      2. Header
      3. Body

      For this stage, you can ignore the body and just focus on `message_size` and the header. You'll learn about response bodies in a later stage.

      #### The `message_size` field

      The [`message_size`](https://kafka.apache.org/protocol.html#protocol_common) field is a 32-bit signed integer. It specifies the size of the header and body.

      For this stage, the tester will only assert that your `message_size` field is 4 bytes long—it won't check the value. You'll implement correct `message_size` values in a later stage.

      #### Header

      Kafka has a few different header versions. The way Kafka determines which header version to use is a bit complicated and is outside the scope of this challenge. For more information, take a look at [KIP-482](https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields) and this [Stack Overflow answer](https://stackoverflow.com/a/71853003).

      In this stage, you will use [response header v0](https://kafka.apache.org/protocol.html#protocol_messages) (scroll down).

      Response header v0 contains a single field: [`correlation_id`](https://developer.confluent.io/patterns/event/correlation-identifier/). This field lets clients match responses to their original requests. Here's how it works:

      1. The client generates a correlation ID.
      2. The client sends a request that includes the correlation ID.
      3. The broker sends a response that includes the same correlation ID.
      4. The client receives the response and matches the correlation ID to the original request.

      The `correlation_id` field is a 32-bit signed integer. For this stage, your program must respond with a hard-coded `correlation_id` of 7.

      ### Tests

      The tester will execute your program like this:
      ```
      $ ./your_program.sh
      ```

      It'll then connect to your broker on port 9092 and send a request:
      ```
      $ echo -n "Placeholder request" | nc -v localhost 9092 | hexdump -C
      ```

      Your broker must send a response with a correlation ID of 7:
      ```java
      00 00 00 00  // message_size:   0 (any value works)
      00 00 00 07  // correlation_id: 7
      ```

      ### Notes

      - For this stage, you don't need to parse the request. You'll learn about request parsing in a later stage.
      - All integers are in [big-endian](https://developer.mozilla.org/en-US/docs/Glossary/Endianness) order.

    marketing_md: |-
      In this stage, you'll start implementing the ResponseHeader.

  - slug: "wa6"
    name: "Parse Correlation ID"
    difficulty: medium
    description_md: |-
      In this stage, you'll replace the hard-coded correlation ID with the actual correlation ID from the request.

      ### Request message

      A request message has three parts:
      1. `message_size`
      2. Header
      3. Body

      To get the `correlation_id` field, you need to find its offset. You already know that `message_size` is 4 bytes long. And here's what the request header looks like (in this stage, we're using [request header v2](https://kafka.apache.org/protocol.html#protocol_messages)):

      | Field                 | Data type         | Description                            |
      | --------------------- | ----------------- | -------------------------------------- |
      | `request_api_key`     | `INT16`           | The API key for the request            |
      | `request_api_version` | `INT16`           | The version of the API for the request |
      | `correlation_id`      | `INT32`           | A unique identifier for the request    |
      | `client_id`           | `NULLABLE_STRING` | The client ID for the request          |
      | `TAG_BUFFER`          | `COMPACT_ARRAY`   | Optional tagged fields                 |

      To learn more about the different data types, see [Protocol Primitive Types](https://kafka.apache.org/protocol.html#protocol_types).

      #### Example

      Here's an example of a request message:
      ```java
      00 00 00 23  // message_size:        35
      00 12        // request_api_key:     18
      00 04        // request_api_version: 4
      6f 7f c6 61  // correlation_id:      1870644833
      ...
      ```

      ### Tests

      The tester will execute your program like this:
      ```
      $ ./your_program.sh
      ```

      It'll then connect to your broker on port 9092 and send a request with a request header v2:
      ```
      $ echo -n "00000023001200046f7fc66100096b61666b612d636c69000a6b61666b612d636c6904302e3100" | xxd -r -p | nc localhost 9092 | hexdump -C
      ```

      Your broker must send a response with the correct correlation ID:
      ```java
      00 00 00 00  // message_size:   0 (any value works)
      6f 7f c6 61  // correlation_id: 1870644833
      ```

      ### Notes

      - For this stage, you don't need to worry about what the request is asking for. You'll handle that in the next stage.
      - For this stage, the tester will only assert that your `message_size` field is 4 bytes long—it won't check the value. You'll implement correct `message_size` values in a later stage.
      - The request header version and response header version are unrelated to each other and do not have to match.
    marketing_md: |-
      In this stage, you'll start decoding the RequestHeader.

  - slug: "nc5"
    name: "Parse API Version"
    difficulty: medium
    description_md: |-
      In this stage, you'll parse the `request_api_version` field in the request header and respond with an error code if the version is invalid.

      ### Kafka APIs

      Every Kafka request is an API call. The Kafka protocol defines over 70 different APIs, all of which do different things. Here are some examples:
      - `Produce` writes events to partitions.
      - `CreateTopics` creates new topics.
      - `ApiVersions` returns the broker's supported API versions.

      A Kafka request specifies the API its calling by using the [`request_api_key`](https://kafka.apache.org/protocol.html#protocol_api_keys) header field.

      ### Message body

      The schemas for the request and response bodies are determined by the API being called.

      For example, here are some of the fields that the [`Produce`](https://kafka.apache.org/protocol.html#The_Messages_Produce) request body contains:

      - The name of the topic to write to.
      - The key of the partition to write to.
      - The event data to write.

      On the other hand, the `Produce` response body contains a response code for each event. These response codes indicate if the writes succeeded.

      As a reminder, requests and responses both have the following format:

      1. `message_size`
      2. Header
      3. Body

      ### API versioning

      Each API supports multiple versions, to allow for different schemas. Here's how API versioning works:
      - Requests use the header field `request_api_version` to specify the API version being requested.
      - Responses always use the same API version as the request. For example, a `Produce Request (Version: 3)` will always get a `Produce Response (Version: 3)` back.
      - Each API's version history is independent. So, different APIs with the same version are unrelated. For example, `Produce Request (Version: 10)` is not related to `Fetch Request (Version: 10)`.

      ### The `ApiVersions` API

      The [`ApiVersions`](https://kafka.apache.org/protocol.html#The_Messages_ApiVersions) API returns the broker's supported API versions. For example, `ApiVersions` may say that the broker supports `Produce` versions 5 to 11, `Fetch` versions 0 to 3, etc.

      In this stage, you'll begin to add support for `ApiVersions` version 4. For this stage, you only need to add support for the `error_code` field. You'll implement the other fields in later stages.

      Note: [ApiVersions v4](https://github.com/apache/kafka/blob/84caaa6e9da06435411510a81fa321d4f99c351f/clients/src/main/resources/common/message/ApiVersionsRequest.json#L25C22-L25C33) isn’t documented yet, but its request and response formats are identical to v3.

      The `ApiVersions` response body begins with `error_code`, a 16-bit signed integer. This field indicates if an error occurred with the request. It's set to 0 if there was no error. To see all the possible values, consult the [error codes chart](https://kafka.apache.org/protocol.html#protocol_error_codes).

      You only need to add support for error code 35, `UNSUPPORTED_VERSION`. This error code occurs when the version of `ApiVersions` requested by the client is not supported by the broker. Assume that your broker only supports versions 0 to 4.

      ### Tests

      The tester will execute your program like this:
      ```
      $ ./your_program.sh  
      ```

      It'll then connect to your broker on port 9092 and send an `ApiVersions` request. This request will ask for an unsupported version of `ApiVersions`:
      ```
      $ echo -n "000000230012674a4f74d28b00096b61666b612d636c69000a6b61666b612d636c6904302e3100" | xxd -r -p | nc localhost 9092 | hexdump -C
      ```
      ```java
      00 00 00 23  // message_size:        35
      00 12        // request_api_key:     18
      67 4a        // request_api_version: 26442
      4f 74 d2 8b  // correlation_id:      1333056139
      ...
      ```

      Your broker must send an `ApiVersions` version 4 response with the `error_code` field set to 35:
      ```java
      00 00 00 00  // message_size:   0 (any value works)
      4f 74 d2 8b  // correlation_id: 1333056139
      00 23        // error_code:     35
      ```

      ### Notes

      - The Kafka protocol's APIs are different from Kafka's [core APIs](https://kafka.apache.org/documentation/#intro_apis). The core APIs are higher-level Java and Scala APIs that wrap around the Kafka protocol.
      - You can assume that the tester will only send you an `ApiVersions` request. You don't need to check the `request_api_key` field in the header.
      - For this stage, the tester will only assert that your `message_size` field is 4 bytes long—it won't check the value. You'll implement correct `message_size` values in a later stage.
    marketing_md: |-
      In this stage, you'll start encoding your response to the `APIVersions` requests.

  - slug: "pv1"
    name: "Handle APIVersions requests"
    difficulty: hard
    description_md: |-
      In this stage, you'll implement the response body for the `APIVersions` request.

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+pv1%3A+Handle+APIVersions+requests&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a valid `APIVersions` (v4) request.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The response body contains at least one entry for the API key `18` (API_VERSIONS).
      - The `MaxVersion` for the `ApiKey` `18` is at least `4`.

      ### Notes

      - The tester will always send you v4 of the APIVersions request.
        - As of Oct 30th 2024, v4 is "unreleased" so isn't available in the Kafka docs yet. It'll
          be available once Kafka 3.9 is released. Here's a link to the [Kafka source code](https://github.com/apache/kafka/blob/84caaa6e9da06435411510a81fa321d4f99c351f/clients/src/main/resources/common/message/ApiVersionsRequest.json#L25C22-L25C33) mentioning this.
        - The structure for v4 is the same as v3 listed in the docs.
      - From this stage onwards, the tester will start validating the first 4 bytes of your response (the "message length") in addition to the other checks.
      - If extra bytes are remaining after decoding all the fields of the response body, this will be considered an error.
    marketing_md: |-
      In this stage, you'll need to implement the `APIVersions:V4` response.

  # Concurrent Requests

  - slug: "nh4"
    name: "Serial requests"
    primary_extension_slug: "concurrent-clients"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for handling multiple sequential requests from the same client.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a `APIVersions` (v4) request, read the response, & validate the response.

      Once a response is received, the tester will re-use the same connection to send multiple other `APIVersions` (v4) requests.

      For each response, the tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The response body contains at least one entry for the API key `18` (API_VERSIONS).
      - The `MaxVersion` for the `ApiKey` `18` is at least `4`.

      ### Notes

      - The tester will only send APIVersions (v4) requests in this stage.
      - If extra bytes are remaining after decoding all the fields of the response body, this will be considered an error.
    marketing_md: |-
      In this stage, you'll need to handle multiple sequential `APIVersions` requests.

  - slug: "sk0"
    name: "Concurrent requests"
    primary_extension_slug: "concurrent-clients"
    difficulty: hard
    description_md: |-
      In this stage, you'll add support for handling concurrent requests from multiple clients.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then instantiate 2-3 clients. Each of these clients will connect to your server on port 9092 and send multiple `APIVersions` (v4) requests.

      For each response, the tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The response body contains at least one entry for the API key `18` (API_VERSIONS).
      - The `MaxVersion` for the `ApiKey` `18` is atleast `4`.

      ### Notes

      - The tester will only send APIVersions (v4) requests in this stage.
      - If extra bytes are remaining after decoding all the fields of the response body, this will be considered an error.
    marketing_md: |-
      In this stage, you'll need to handle concurrent `APIVersions` requests.

  # Describe Topic Partitions

  - slug: "yk1"
    primary_extension_slug: "listing-partitions"
    name: "Include DescribeTopicPartitions in APIVersions"
    difficulty: medium
    description_md: |-
      In this stage, you'll add an entry for the `DescribeTopicPartitions` API to the APIVersions response.

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+yk1%3A+Include+DescribeTopicPartitions+in+APIVersions&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh /tmp/server.properties
      ```

      It'll then connect to your server on port 9092 and send a valid `APIVersions` (v4) request.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The response body contains at least one entry for the API key 18 (`APIVersions`) and one entry for the API key 75 (`DescribeTopicPartitions`).
      - The response for the API key 18 (`APIVersions`) has a `MaxVersion` of at least 4, and a `MinVersion` of at least 0.
      - The response for the API key 75 (`DescribeTopicPartitions`) has a `MaxVersion` of at least 0, and a `MinVersion` of at least 0.

      ### Notes

      - The `MaxVersion` for the `DescribeTopicPartitions` and `APIVersions` are different. For `APIVersions`, it is 4. For `DescribeTopicPartitions`, it is 0.
      - You'll still need to include the entry for `APIVersions` in your response to pass previous stages.
      - We'll get to implementing the `DescribeTopicPartitions` request in later stages, in this stage you only need to add an entry to the APIVersions response.
    marketing_md: |-
      In this stage, you'll add the DescribeTopicPartitions API to the APIVersions response.

  - slug: "vt6"
    primary_extension_slug: "listing-partitions"
    name: "List for an unknown topic"
    difficulty: medium
    description_md: |-
      In this stage, you'll implement the `DescribeTopicPartitions` response for an unknown topic.

      We've created an interactive protocol inspector for the `DescribeTopicPartitions` request & response:

      - 🔎 [DescribeTopicPartitions Request (v0)](https://binspec.org/kafka-describe-topic-partitions-request-v0)
      - 🔎 [DescribeTopicPartitions Response (v0) - Unknown Topic](https://binspec.org/kafka-describe-topic-partitions-response-v0-unknown-topic)

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+vt6%3A+List+for+an+unknown+topic&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh /tmp/server.properties
      ```

      It'll then connect to your server on port 9092 and send a `DescribeTopicPartitions` (v0) request. The request will contain a single topic with 1 partition.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is 3 (`UNKNOWN_TOPIC_OR_PARTITION`).
      - The response body should be valid DescribeTopicPartitions (v0) Response.
      - The `topic_name` field in the response should be equal to the topic name sent in the request.
      - The `topic_id` field in the response should be equal to `00000000-0000-0000-0000-000000000000`.
      - The `partitions` field in the response should be empty. (As there are no partitions assigned to this non-existent topic.)

      ### Notes

      - You'll need to parse the `DescribeTopicPartitions` request in this stage to get the topic name to send in the response.
      - For now, you can assume that all topics are "unknown". We'll work on identifying actual vs. unknown topics in later stages.
      - The official docs for the `DescribeTopicPartitions` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_DescribeTopicPartitions).

    marketing_md: |-
      In this stage, you'll implement the DescribeTopicPartition response for an unknown topic.

  - slug: "ea7"
    primary_extension_slug: "listing-partitions"
    name: "List for a single partition"
    difficulty: hard
    description_md: |-
      In this stage, you'll implement the `DescribeTopicPartitions` response for a single topic.

      Kafka stores metadata about topics in the `__cluster_metadata` topic. To check if a topic exists or not, you'll need to read
      the `__cluster_metadata` topic's log file, located at `/tmp/kraft-combined-logs/__cluster_metadata-0/00000000000000000000.log`.

      We've created an interactive protocol inspector for the cluster metadata log file and the `DescribeTopicPartitions` response:

      - 🔎 [Cluster Metadata Log File](https://binspec.org/kafka-cluster-metadata)
      - 🔎 [DescribeTopicPartitions Response (v0)](https://binspec.org/kafka-describe-topic-partitions-response-v0)

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+ea7%3A+List+for+a+single+partition&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh /tmp/server.properties
      ```

      It'll then connect to your server on port 9092 and send a `DescribeTopicPartitions` (v0) request. The request will contain an single topic name. The topic exists and has a single partition assigned to it.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is 0 (no error).
      - The response body should be valid DescribeTopicPartitions (v0) Response.
      - The `topic_name` field in the response should match the topic name sent in the request.
      - The `topic_id` field in the response should match the topic UUID of the topic.
      - The `partitions` field in the response should contain details of the partition assigned to the topic.
      - The error code in the partition response should be 0 (no error).
      - The `partition_index` field in the partition response should match the partition ID of the partition assigned to the topic.

      ### Notes

      - The official docs for the `DescribeTopicPartitions` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_DescribeTopicPartitions).
      - The official Kafka docs don't cover the structure of records inside the `__cluster_metadata` topic, but you can find the definitions in the Kafka source code [here](https://github.com/apache/kafka/tree/5b3027dfcbcb62d169d4b4421260226e620459af/metadata/src/main/resources/common/metadata).

    marketing_md: |-
      In this stage, you'll implement the DescribeTopicPartition response for a single topic.

  - slug: "ku4"
    primary_extension_slug: "listing-partitions"
    name: "List for multiple partitions"
    difficulty: hard
    description_md: |-
      In this stage, you'll implement the `DescribeTopicPartitions` response for a single topic with multiple partitions.

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+KU4+%28DescribeTopicPartition+with+single+topic+but+multiple+partitions%29&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh /tmp/server.properties
      ```

      It'll then connect to your server on port 9092 and send a `DescribeTopicPartitions` (v0) request. The request will contain an single topic name. The topic exists and has 2 partitions assigned to it.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (NO_ERROR).
      - The response body should be valid DescribeTopicPartitionResponse.
      - The `topic_name` field in the response should be equal to the topic name sent in the request.
      - The `topic_id` field in the response should be equal to the topic UUID of the topic.
      - The partition response should contain details of the 2 partitions assigned to the topic.
      - There should be 2 partition responses.
      - The error code in both the partition responses should be `0` (NO_ERROR).
      - The `partition_index` field in both the partition responses should be equal to the partition ID of the partition assigned to the topic.

      ### Notes

      - The official docs for the `DescribeTopicPartitions` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_DescribeTopicPartitions).

    marketing_md: |-
      In this stage, you'll implement the DescribeTopicPartition response for a single topic with multiple partitions.

  - slug: "wq2"
    primary_extension_slug: "listing-partitions"
    name: "List for multiple topics"
    difficulty: hard
    description_md: |-
      In this stage, you'll implement the `DescribeTopicPartitions` response for multiple topics.

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+WQ2+%28DescribeTopicPartition+with+multiple+topics%29&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh /tmp/server.properties
      ```

      It'll then connect to your server on port 9092 and send a `DescribeTopicPartitions` (v0) request. The request will contain 3 topic names. The topics exist and have 1 or 2 partitions assigned to each.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the topic response body is `0` (NO_ERROR).
      - The `topic_name` field in the topic response should be equal to the topic name sent in the request.
      - The `topic_id` field in the topic response should be equal to the topic UUID of the topic.
      - The partition response should contain details of the partitions assigned to the topic.
      - The error code in all the partition responses should be `0` (NO_ERROR).
      - The `partition_index` field in all the partition responses should be equal to the partition ID of the partition assigned to the topic.

      ### Notes

      - The official docs for the `DescribeTopicPartitions` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_DescribeTopicPartitions).

    marketing_md: |-
      In this stage, you'll implement the DescribeTopicPartition response for multiple topics.

  # Consuming Messages

  - slug: "gs0"
    primary_extension_slug: "consuming-messages"
    name: "Include Fetch in APIVersions"
    difficulty: medium
    description_md: |-
      In this stage, you'll add an entry for the `Fetch` API to the APIVersions response.

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+gs0%3A+Include+Fetch+in+APIVersions&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a valid `APIVersions` (v4) request.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The response body contains at least one entry for the API key `1` (FETCH).
      - The `MaxVersion` for the Fetch API is atleast 16.

      ### Notes

      - You don't have to implement support for the `Fetch` request in this stage. We'll get to this in later stages.
      - You'll still need to include the entry for `APIVersions` in your response to pass the previous stage.
      - The `MaxVersion` for the `Fetch` and `APIVersions` are different. For `APIVersions`, it is 4. For `Fetch`, it is 16.
    marketing_md: |-
      In this stage, you'll add the Fetch API to the APIVersions response.

  - slug: "dh6"
    primary_extension_slug: "consuming-messages"
    name: "Fetch with no topics"
    difficulty: medium
    description_md: |-
      In this stage, you'll implement the Fetch response for a Fetch request with no topics.

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+dh6%3A+Fetch+with+no+topics&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a `Fetch` (v16) request. The request will contain an empty array of topics.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The `throttle_time_ms` field in the response is `0`.
      - The `session_id` field in the response is `0`.
      - The `responses` field in the response has 0 elements (since the request had an empty array of topics).

      <!--
      ```
      0000   00 00 00 11 5e 33 46 cc 00 00 00 00 00 00 00 0a   ....^3F.........
      0010   b9 c1 2e 01 00                                    .....
      ```
      -->

      ### Notes

      - You don't need to parse the fields in the `Fetch` request in this stage, we'll get to this in later stages.
      - The official docs for the `Fetch` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_Fetch). Make sure
        to scroll down to the "Fetch Response (Version: 16)" section.
    marketing_md: |-
      In this stage, you'll start encoding your response to the `Fetch` requests.

  - slug: "hn6"
    primary_extension_slug: "consuming-messages"
    name: "Fetch with an unknown topic"
    difficulty: medium
    description_md: |-
      In this stage, you'll implement the Fetch response for an unknown topic.

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+hn6%3A+Fetch+with+an+unknown+topic&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a `Fetch` (v16) request. This request will contain a single topic with an unknown topic ID (i.e. the topic doesn't exist yet).

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The `throttle_time_ms` field in the response is `0`.
      - The `responses` field in the response has 1 element, and in that element:
        - The `topic_id` field matches what was sent in the request.
        - The `partitions` array has 1 element, and in that element:
          - The `partition_index` field is `0`.
          - The `error_code` field is `100` (UNKNOWN_TOPIC).

      ### Notes

      - You'll need to parse the `Fetch` request in this stage to get the `topic_id` to send in the response.
      - The official docs for the `Fetch` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_Fetch). Make sure
        to scroll down to the "Fetch Response (Version: 16)" section.
    marketing_md: |-
      In this stage, you'll start encoding your response to the `Fetch` requests.

  - slug: "cm4"
    primary_extension_slug: "consuming-messages"
    name: "Fetch with an empty topic"
    difficulty: medium
    description_md: |-
      In this stage, you'll implement the Fetch response for a topic with no messages.

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+cm4%3A+Fetch+with+an+empty+topic&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a `Fetch` (v16) request. The request will contain a single topic with a topic ID that exists. However, the topic has no messages assigned to it (i.e. the log file is empty).

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The `throttle_time_ms` field in the response is `0`.
      - The `responses` field in the response has 1 element, and in that element:
        - The `topic_id` field matches what was sent in the request.
        - The `partitions` array has 1 element, and in that element:
          - The `partition_index` field is `0`.
          - The `error_code` field is `0` (No Error).
          - The `records` array has `0` elements.

      ### Notes

      - You'll need to parse the `Fetch` request in this stage to get the `topic_id` to send in the response.
      - The official docs for the `Fetch` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_Fetch). Make sure
        to scroll down to the "Fetch Response (Version: 16)" section.

    marketing_md: |-
      In this stage, you'll implement the Fetch response for a topic with no messages.

  - slug: "eg2"
    primary_extension_slug: "consuming-messages"
    name: "Fetch single message from disk"
    difficulty: hard
    description_md: |-
      In this stage, you'll implement the Fetch response for a topic with a single message, reading it from disk.

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+eg2%3A+Fetch+single+message+from+disk&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a `Fetch` (v16) request. The request will contain a single topic with a topic ID that exists. The topic has a single message assigned to it.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The `throttle_time_ms` field in the response is `0`.
      - The `responses` field in the response has 1 element, and in that element:
        - The `topic_id` field matches what was sent in the request.
        - The `partitions` array has 1 element, and in that element:
          - The `partition_index` field is `0`.
          - The `error_code` field is `0` (No Error).
          - The `records` array has 1 element.
            - The entire `RecordBatch` content is read from disk. (We will compare the contents of the `RecordBatch` with the contents of the log file to verify this.)

      ### Notes

      - You'll need to parse the `Fetch` request in this stage to get the `topic_id` to send in the response.
      - The official docs for the `Fetch` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_Fetch). Make sure
        to scroll down to the "Fetch Response (Version: 16)" section.

    marketing_md: |-
      In this stage, you'll implement the Fetch response for a topic with a single message, reading it from disk.

  - slug: "fd8"
    primary_extension_slug: "consuming-messages"
    name: "Fetch multiple messages from disk"
    difficulty: hard
    description_md: |-
      In this stage, you'll implement the Fetch response for a topic with multiple messages, reading them from disk.

      🚧 **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+fd8%3A+Fetch+multiple+messages+from+disk&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a `Fetch` (v16) request. The request will contain a single topic with a topic ID that exists. The topic has multiple messages assigned to it (but written to a single partition).

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The `throttle_time_ms` field in the response is `0`.
      - The `responses` field in the response has 1 element, and in that element:
        - The `topic_id` field matches what was sent in the request.
        - The `partitions` array has 1 element, and in that element:
          - The `partition_index` field matches what was sent in the request.
          - The `error_code` field is `0` (No Error).
          - The `records` array has the correct number of elements.
            - The entire `RecordBatch` content is read from disk. (We will compare the contents of the `RecordBatch` with the contents of the log file to verify this.)

      ### Notes

      - You'll need to parse the `Fetch` request in this stage to get the `topic_id` to send in the response.
      - The official docs for the `Fetch` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_Fetch). Make sure
        to scroll down to the "Fetch Response (Version: 16)" section.

    marketing_md: |-
      In this stage, you'll implement the Fetch response for a topic with multiple messages, reading them from disk.

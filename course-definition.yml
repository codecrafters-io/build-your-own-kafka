slug: "kafka"
name: "Build your own Kafka"
short_name: "Kafka"
release_status: "beta"

description_md: |-
  Apache Kafka is a distributed event streaming platform often used for high-performance data pipelines. In this challenge, you'll build your own Kafka broker
  that's capable of serving basic requests.

  Along the way you'll learn about TCP servers, the Kafka wire protocol and more.

short_description_md: |-
  Learn about TCP servers, the Kafka wire protocol and more.

completion_percentage: 15

languages:
  - slug: "gleam"
  - slug: "go"
  - slug: "java"
  - slug: "javascript"
  - slug: "python"
  - slug: "rust"

marketing:
  difficulty: medium
  sample_extension_idea_title: "On Disk Storage"
  sample_extension_idea_description: "A Kafka broker that can read and write to disk"
  testimonials:
    - author_name: "Ananthalakshmi Sankar"
      author_description: "Automation Engineer at Apple"
      author_avatar: "https://codecrafters.io/images/external/testimonials/oxta.jpeg"
      link: "https://github.com/anu294"
      text: "There are few sites I like as much that have a step by step guide. The real-time feedback is so good, it's creepy!"

    - author_name: "Patrick Burris"
      author_description: "Senior Software Developer, CenturyLink"
      author_avatar: "https://codecrafters.io/images/external/testimonials/patrick-burris.jpeg"
      link: "https://github.com/Jumballaya"
      text: |-
        I think the instant feedback right there in the git push is really cool.
        Didn't even know that was possible!

extensions:
  - slug: "concurrent-clients"
    name: "Concurrent Clients"
    description_markdown: |
      In this challenge extension you'll add support for serving multiple clients simultaneously.

      Along the way you'll learn about TCP connections, how to handle concurrency and more.

  - slug: "listing-partitions"
    name: "Listing Partitions"
    description_markdown: |
      In this challenge extension you'll add support for listing topic partitions by implementing the [DescribeTopicPartitions][describe-topic-partitions] API.

      Along the way you'll learn about how Kafka stores messages on disk, the `__cluster_metadata` topic and more.

      [describe-topic-partitions]: https://kafka.apache.org/protocol.html#The_Messages_DescribeTopicPartitions

  - slug: "consuming-messages"
    name: "Consuming Messages"
    description_markdown: |
      In this challenge extension you'll add support for consuming messages by implementing the [Fetch][fetch-api] API.

      Along the way you'll learn about how Kafka's Fetch API works, how Kafka stores messages on disk and more.

      [fetch-api]: https://kafka.apache.org/protocol.html#The_Messages_Fetch

stages:
  - slug: "vi6"
    name: "Bind to a port"
    difficulty: easy
    description_md: |-
      In this stage, you'll implement a TCP server that listens on port 9092.

      [TCP](https://en.wikipedia.org/wiki/Transmission_Control_Protocol) is the underlying protocol that Kafka brokers and clients use to communicate with each other.

      ### Tests

      The tester will execute your program like this:
      ```
      $ ./your_program.sh
      ```

      It'll then try to connect to your TCP server on port 9092. If the connection succeeds, you'll pass this stage.

      ### Notes

      - If you already have a Kafka broker running on port 9092 and you run your program, you'll get a "port already in use" error. To fix this, terminate the existing Kafka broker and run your program again.
      - 9092 is the default port that Kafka uses.
    marketing_md: |-
      In this stage, you'll start a TCP server on port 9092, which is the
      default port that Kafka uses.

  - slug: "nv3"
    name: "Send Correlation ID"
    difficulty: easy
    description_md: |-
      In this stage, you'll send a response with a correlation ID.

      ### Response message

      Kafka brokers communicate with clients through the [Kafka wire protocol](https://kafka.apache.org/protocol.html). The protocol uses a request-response model, where the client sends a request message and the broker replies with a response message.

      A Kafka response message has three parts:
      1. Message size
      2. Header
      3. Body

      For this stage, you can ignore the body and just focus on the message size and header. You'll learn about response bodies in a later stage.

      #### Message size

      The [message size](https://kafka.apache.org/protocol.html#protocol_common) is a 32-bit signed integer. It specifies the size of the header and body.

      For this stage, the tester will only assert that your message size is 4 bytes longâ€”it won't check its value. You'll implement correct message sizes in a later stage.

      #### Header

      Kafka has a few different header versions. The way Kafka determines which header version to use is a bit complicated and is outside the scope of this challenge. For more information, take a look at [KIP-482](https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields) and this [Stack Overflow answer](https://stackoverflow.com/a/71853003).

      In this stage, you will use [response header v0](https://kafka.apache.org/protocol.html#protocol_messages) (scroll down).

      It has a single value: a [correlation ID](https://developer.confluent.io/patterns/event/correlation-identifier/). This value lets clients match responses to their original requests. Here's how it works:

      1. The client generates a correlation ID.
      2. The client sends a request that includes the correlation ID.
      3. The broker sends a response that includes the same correlation ID.
      4. The client receives the response and matches the correlation ID to the original request.

      The correlation ID is a 32-bit signed integer. For this stage, your program must respond with a hard-coded correlation ID of 7.

      ### Tests

      The tester will execute your program like this:
      ```
      $ ./your_program.sh
      ```

      It'll then connect to your broker on port 9092 and send a request:
      ```
      $ echo -n "Placeholder request" | nc -v localhost 9092 | hexdump -C
      ```

      Your broker must send a response with a correlation ID of 7:
      ```java
      00 00 00 00  // Message size:   0 (any value works)
      00 00 00 07  // Correlation ID: 7
      ```

      ### Notes

      - For this stage, you don't need to parse the request. You'll learn about request parsing in a later stage.
      - All integers are in [big-endian](https://developer.mozilla.org/en-US/docs/Glossary/Endianness) order.

    marketing_md: |-
      In this stage, you'll start implementing the ResponseHeader.

  - slug: "wa6"
    name: "Parse Correlation ID"
    difficulty: medium
    description_md: |-
      In this stage, you'll parse the correlation ID from a request and send a response with the same correlation ID.

      ### Request header format

      In the previous stage, we saw that the request starts with a 4 byte length field, followed by the request header, and then the request body.

      The format of the request header is as follows:

      | Field Name            | Field Type      | Description                               |
      |-----------------------|-----------------|-------------------------------------------|
      | `request_api_key`     | INT16           | The API key for the request               |
      | `request_api_version` | INT16           | The version of the API for the request    |
      | `correlation_id`      | INT32           | A unique identifier for the request       |
      | `client_id`           | NULLABLE_STRING | The client ID for the request             |
      | `tagged_fields`       | TAGGED_FIELDS   | Optional tagged fields                    |

      The documentation for this can be found [here](https://kafka.apache.org/protocol.html#protocol_messages) under the "Request Header v2" section.

      - `request_api_key`: An integer identifying the request type.
        - The value of this field is different for each type of request.
        - For example, the `APIVersions` request has a `request_api_key` of `18`.
        - A full list of API keys can be found in [the docs](https://kafka.apache.org/protocol.html#protocol_api_keys).
      - `request_api_version`: The version of the API to use for the request.
        - For example, the `APIVersions` request supports multiple versions: 0, 1, 2, 3 and 4.
      - `correlation_id`: A unique identifier for the request.
        - This value is echo-ed back in the response.
        - (This is the value you hardcoded in the previous stage!)
      - `client_id`: A string identifying the client that sent the request.
      - `tagged_fields`: Optional tagged fields
        - This can be ignored for now, they're [optional tagged fields](https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields) used to introduce additional features over time.
        - The value for this will always be a null byte in this challenge (i.e. no tagged fields are present)

      In this stage, you'll only need to parse the `correlation_id` field from the request. You can ignore the other fields for now.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a `APIVersions` (v4) request. The tester will include a random
      correlation ID in this request.

      The tester will wait for your program to respond and it'll then validate that the correlation ID in the response header matches the correlation ID it sent in the request header.

      Just like the previous stage, the tester won't validate the first 4 bytes of your response (the "message length") in this stage.

      ### Notes

      - You can remove the hardcoded correlation ID of `7` we used in the previous stage. You'll now need to read this value from the request.
      - Since the response format is currently incomplete, the first 4 bytes of your response (the "message length") will not be validated in this stage. We'll get to this in later stages.
      - You don't need to parse all fields in the request in this stage, just the `correlation_id` field. We'll get to the other fields in later stages.
    marketing_md: |-
      In this stage, you'll start decoding the RequestHeader.

  - slug: "nc5"
    name: "Parse API Version"
    difficulty: medium
    description_md: |-
      In this stage, you'll parse the `api_version` field from a request and respond with an error if the version is unsupported.

      ðŸš§ **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+nc5%3A+Parse+API+Version&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a `APIVersions` request. This request will include an invalid `APIVersion` (Examples: `-1` or `1234`).

      Any version other than 0, 1, 2, 3 and 4 should be considered an invalid version.

      Your server should respond with an error code of `35` (UNSUPPORTED_VERSION).

      The tester will validate that:

      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `35` (UNSUPPORTED_VERSION).

      The tester won't validate the first 4 bytes of your response (the "message length") in this stage. We'll get to this in later stages.

      ### Notes

      - The `APIVersions` request will be sent with an invalid `APIVersion` (Examples: `-1` or `1234`).
    marketing_md: |-
      In this stage, you'll start encoding your response to the `APIVersions` requests.

  - slug: "pv1"
    name: "Handle APIVersions requests"
    difficulty: hard
    description_md: |-
      In this stage, you'll implement the response body for the `APIVersions` request.

      ðŸš§ **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+pv1%3A+Handle+APIVersions+requests&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a valid `APIVersions` (v4) request.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The response body contains at least one entry for the API key `18` (API_VERSIONS).
      - The `MaxVersion` for the `ApiKey` `18` is at least `4`.

      ### Notes

      - The tester will always send you v4 of the APIVersions request.
      - From this stage onwards, the tester will start validating the first 4 bytes of your response (the "message length") in addition to the other checks.
      - If extra bytes are remaining after decoding all the fields of the response body, this will be considered an error.
    marketing_md: |-
      In this stage, you'll need to implement the `APIVersions:V4` response.

  # Concurrent Requests

  - slug: "nh4"
    name: "Serial requests"
    primary_extension_slug: "concurrent-clients"
    difficulty: medium
    description_md: |-
      In this stage, you'll add support for handling multiple sequential requests from the same client.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a `APIVersions` (v4) request, read the response, & validate the response.

      Once a response is received, the tester will re-use the same connection to send multiple other `APIVersions` (v4) requests.

      For each response, the tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The response body contains at least one entry for the API key `18` (API_VERSIONS).
      - The `MaxVersion` for the `ApiKey` `18` is at least `4`.

      ### Notes

      - The tester will only send APIVersions (v4) requests in this stage.
      - If extra bytes are remaining after decoding all the fields of the response body, this will be considered an error.
    marketing_md: |-
      In this stage, you'll need to handle multiple sequential `APIVersions` requests.

  - slug: "sk0"
    name: "Concurrent requests"
    primary_extension_slug: "concurrent-clients"
    difficulty: hard
    description_md: |-
      In this stage, you'll add support for handling concurrent requests from multiple clients.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then instantiate 2-3 clients. Each of these clients will connect to your server on port 9092 and send multiple `APIVersions` (v4) requests.

      For each response, the tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The response body contains at least one entry for the API key `18` (API_VERSIONS).
      - The `MaxVersion` for the `ApiKey` `18` is atleast `4`.

      ### Notes

      - The tester will only send APIVersions (v4) requests in this stage.
      - If extra bytes are remaining after decoding all the fields of the response body, this will be considered an error.
    marketing_md: |-
      In this stage, you'll need to handle concurrent `APIVersions` requests.

  # Describe Topic Partitions

  - slug: "yk1"
    primary_extension_slug: "listing-partitions"
    name: "Include DescribeTopicPartitions in APIVersions"
    difficulty: medium
    description_md: |-
      In this stage, you'll add an entry for the `DescribeTopicPartitions` API to the APIVersions response.

      ðŸš§ **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+yk1%3A+Include+DescribeTopicPartitions+in+APIVersions&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh /tmp/server.properties
      ```

      It'll then connect to your server on port 9092 and send a valid `APIVersions` (v4) request.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The response body contains at least one entry for the API key 18 (`APIVersions`) and one entry for the API key 75 (`DescribeTopicPartitions`).
      - The response for the API key 18 (`APIVersions`) has a `MaxVersion` of at least 4, and a `MinVersion` of at least 0.
      - The response for the API key 75 (`DescribeTopicPartitions`) has a `MaxVersion` of at least 0, and a `MinVersion` of at least 0.

      ### Notes

      - The `MaxVersion` for the `DescribeTopicPartitions` and `APIVersions` are different. For `APIVersions`, it is 4. For `DescribeTopicPartitions`, it is 0.
      - You'll still need to include the entry for `APIVersions` in your response to pass previous stages.
      - We'll get to implementing the `DescribeTopicPartitions` request in later stages, in this stage you only need to add an entry to the APIVersions response.
    marketing_md: |-
      In this stage, you'll add the DescribeTopicPartitions API to the APIVersions response.

  - slug: "vt6"
    primary_extension_slug: "listing-partitions"
    name: "List for an unknown topic"
    difficulty: medium
    description_md: |-
      In this stage, you'll implement the `DescribeTopicPartitions` response for an unknown topic.

      We've created an interactive protocol inspector for the `DescribeTopicPartitions` request & response:

      - ðŸ”Ž [DescribeTopicPartitions Request (v0)](https://binspec.org/kafka-describe-topic-partitions-request-v0)
      - ðŸ”Ž [DescribeTopicPartitions Response (v0) - Unknown Topic](https://binspec.org/kafka-describe-topic-partitions-response-v0-unknown-topic)

      ðŸš§ **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+vt6%3A+List+for+an+unknown+topic&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh /tmp/server.properties
      ```

      It'll then connect to your server on port 9092 and send a `DescribeTopicPartitions` (v0) request. The request will contain a single topic with 1 partition.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is 3 (`UNKNOWN_TOPIC_OR_PARTITION`).
      - The response body should be valid DescribeTopicPartitions (v0) Response.
      - The `topic_name` field in the response should be equal to the topic name sent in the request.
      - The `topic_id` field in the response should be equal to `00000000-0000-0000-0000-000000000000`.
      - The `partitions` field in the response should be empty. (As there are no partitions assigned to this non-existent topic.)

      ### Notes

      - You'll need to parse the `DescribeTopicPartitions` request in this stage to get the topic name to send in the response.
      - For now, you can assume that all topics are "unknown". We'll work on identifying actual vs. unknown topics in later stages.
      - The official docs for the `DescribeTopicPartitions` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_DescribeTopicPartitions).

    marketing_md: |-
      In this stage, you'll implement the DescribeTopicPartition response for an unknown topic.

  - slug: "ea7"
    primary_extension_slug: "listing-partitions"
    name: "List for a single partition"
    difficulty: hard
    description_md: |-
      In this stage, you'll implement the `DescribeTopicPartitions` response for a single topic.

      Kafka stores metadata about topics in the `__cluster_metadata` topic. To check if a topic exists or not, you'll need to read
      the `__cluster_metadata` topic's log file, located at `/tmp/kraft-combined-logs/__cluster_metadata-0/00000000000000000000.log`.

      We've created an interactive protocol inspector for the cluster metadata log file and the `DescribeTopicPartitions` response:

      - ðŸ”Ž [Cluster Metadata Log File](https://binspec.org/kafka-cluster-metadata)
      - ðŸ”Ž [DescribeTopicPartitions Response (v0)](https://binspec.org/kafka-describe-topic-partitions-response-v0)

      ðŸš§ **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+ea7%3A+List+for+a+single+partition&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh /tmp/server.properties
      ```

      It'll then connect to your server on port 9092 and send a `DescribeTopicPartitions` (v0) request. The request will contain an single topic name. The topic exists and has a single partition assigned to it.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is 0 (no error).
      - The response body should be valid DescribeTopicPartitions (v0) Response.
      - The `topic_name` field in the response should match the topic name sent in the request.
      - The `topic_id` field in the response should match the topic UUID of the topic.
      - The `partitions` field in the response should contain details of the partition assigned to the topic.
      - The error code in the partition response should be 0 (no error).
      - The `partition_index` field in the partition response should match the partition ID of the partition assigned to the topic.

      ### Notes

      - The official docs for the `DescribeTopicPartitions` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_DescribeTopicPartitions).
      - The official Kafka docs don't cover the structure of records inside the `__cluster_metadata` topic, but you can find the definitions in the Kafka source code [here](https://github.com/apache/kafka/tree/5b3027dfcbcb62d169d4b4421260226e620459af/metadata/src/main/resources/common/metadata).

    marketing_md: |-
      In this stage, you'll implement the DescribeTopicPartition response for a single topic.

  - slug: "ku4"
    primary_extension_slug: "listing-partitions"
    name: "List for multiple partitions"
    difficulty: hard
    description_md: |-
      In this stage, you'll implement the `DescribeTopicPartitions` response for a single topic with multiple partitions.

      ðŸš§ **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+KU4+%28DescribeTopicPartition+with+single+topic+but+multiple+partitions%29&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh /tmp/server.properties
      ```

      It'll then connect to your server on port 9092 and send a `DescribeTopicPartitions` (v0) request. The request will contain an single topic name. The topic exists and has 2 partitions assigned to it.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (NO_ERROR).
      - The response body should be valid DescribeTopicPartitionResponse.
      - The `topic_name` field in the response should be equal to the topic name sent in the request.
      - The `topic_id` field in the response should be equal to the topic UUID of the topic.
      - The partition response should contain details of the 2 partitions assigned to the topic.
      - There should be 2 partition responses.
      - The error code in both the partition responses should be `0` (NO_ERROR).
      - The `partition_index` field in both the partition responses should be equal to the partition ID of the partition assigned to the topic.

      ### Notes

      - The official docs for the `DescribeTopicPartitions` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_DescribeTopicPartitions).

    marketing_md: |-
      In this stage, you'll implement the DescribeTopicPartition response for a single topic with multiple partitions.

  - slug: "wq2"
    primary_extension_slug: "listing-partitions"
    name: "List for multiple topics"
    difficulty: hard
    description_md: |-
      In this stage, you'll implement the `DescribeTopicPartitions` response for multiple topics.

      ðŸš§ **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+WQ2+%28DescribeTopicPartition+with+multiple+topics%29&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh /tmp/server.properties
      ```

      It'll then connect to your server on port 9092 and send a `DescribeTopicPartitions` (v0) request. The request will contain 3 topic names. The topics exist and have 1 or 2 partitions assigned to each.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the topic response body is `0` (NO_ERROR).
      - The `topic_name` field in the topic response should be equal to the topic name sent in the request.
      - The `topic_id` field in the topic response should be equal to the topic UUID of the topic.
      - The partition response should contain details of the partitions assigned to the topic.
      - The error code in all the partition responses should be `0` (NO_ERROR).
      - The `partition_index` field in all the partition responses should be equal to the partition ID of the partition assigned to the topic.

      ### Notes

      - The official docs for the `DescribeTopicPartitions` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_DescribeTopicPartitions).

    marketing_md: |-
      In this stage, you'll implement the DescribeTopicPartition response for multiple topics.

  # Consuming Messages

  - slug: "gs0"
    primary_extension_slug: "consuming-messages"
    name: "Include Fetch in APIVersions"
    difficulty: medium
    description_md: |-
      In this stage, you'll add an entry for the `Fetch` API to the APIVersions response.

      ðŸš§ **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+gs0%3A+Include+Fetch+in+APIVersions&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a valid `APIVersions` (v4) request.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The response body contains at least one entry for the API key `1` (FETCH).
      - The `MaxVersion` for the Fetch API is atleast 16.

      ### Notes

      - You don't have to implement support for the `Fetch` request in this stage. We'll get to this in later stages.
      - You'll still need to include the entry for `APIVersions` in your response to pass the previous stage.
      - The `MaxVersion` for the `Fetch` and `APIVersions` are different. For `APIVersions`, it is 4. For `Fetch`, it is 16.
    marketing_md: |-
      In this stage, you'll add the Fetch API to the APIVersions response.

  - slug: "dh6"
    primary_extension_slug: "consuming-messages"
    name: "Fetch with no topics"
    difficulty: medium
    description_md: |-
      In this stage, you'll implement the Fetch response for a Fetch request with no topics.

      ðŸš§ **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+dh6%3A+Fetch+with+no+topics&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a `Fetch` (v16) request. The request will contain an empty array of topics.

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The `throttle_time_ms` field in the response is present (any value is accepted).
      - The `session_id` field in the response is `0`.
      - The `responses` field in the response has 0 elements (since the request had an empty array of topics).

      <!--
      ```
      0000   00 00 00 11 5e 33 46 cc 00 00 00 00 00 00 00 0a   ....^3F.........
      0010   b9 c1 2e 01 00                                    .....
      ```
      -->

      ### Notes

      - You don't need to parse the fields in the `Fetch` request in this stage, we'll get to this in later stages.
      - The official docs for the `Fetch` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_Fetch). Make sure
        to scroll down to the "Fetch Response (Version: 16)" section.
    marketing_md: |-
      In this stage, you'll start encoding your response to the `Fetch` requests.

  - slug: "hn6"
    primary_extension_slug: "consuming-messages"
    name: "Fetch with an unknown topic"
    difficulty: medium
    description_md: |-
      In this stage, you'll implement the Fetch response for an unknown topic.

      ðŸš§ **We're still working on instructions for this stage**. You can find notes on how the tester works below.

      In the meantime, please use
      [this link](https://forum.codecrafters.io/new-topic?category=Challenges&tags=challenge%3Akafka&title=Question+about+hn6%3A+Fetch+with+an+unknown+topic&body=%3Cyour+question+here%3E)
      to ask questions on the forum.

      ### Tests

      The tester will execute your program like this:

      ```bash
      $ ./your_program.sh
      ```

      It'll then connect to your server on port 9092 and send a `Fetch` (v16) request. This request will contain a single topic with an unknown topic ID (i.e. the topic doesn't exist yet).

      The tester will validate that:

      - The first 4 bytes of your response (the "message length") are valid.
      - The correlation ID in the response header matches the correlation ID in the request header.
      - The error code in the response body is `0` (No Error).
      - The `throttle_time_ms` field in the response is present (any value is accepted).
      - The `session_id` field in the response is `0`.
      - The `responses` field in the response has 1 element, and in that element:
        - The `topic_id` field matches what was sent in the request.
        - The `partitions` array has 1 element, and in that element:
          - The `partition_index` field is `0`.
          - The `error_code` field is `100` (UNKNOWN_TOPIC).

      ### Notes

      - You'll need to parse the `Fetch` request in this stage to get the `topic_id` to send in the response.
      - The official docs for the `Fetch` request can be found [here](https://kafka.apache.org/protocol.html#The_Messages_Fetch). Make sure
        to scroll down to the "Fetch Response (Version: 16)" section.
    marketing_md: |-
      In this stage, you'll start encoding your response to the `Fetch` requests.

  - slug: "cm4"
    primary_extension_slug: "consuming-messages"
    name: "Fetch with an empty topic"
    difficulty: hard
    description_md: |-
      ðŸš§ **We're still working on tests for this stage!**.
    marketing_md: |-
      In this stage, you'll implement the Fetch response for a topic with multiple messages.

  - slug: "eg2"
    primary_extension_slug: "consuming-messages"
    name: "Fetch single message from disk"
    difficulty: hard
    description_md: |-
      ðŸš§ **We're still working on tests for this stage!**.
    marketing_md: |-
      In this stage, you'll implement the Fetch response for a topic with a single message, reading it from disk.

  - slug: "fd8"
    primary_extension_slug: "consuming-messages"
    name: "Fetch multiple messages from disk"
    difficulty: hard
    description_md: |-
      ðŸš§ **We're still working on tests for this stage!**.
    marketing_md: |-
      In this stage, you'll implement the Fetch response for a topic with multiple messages, reading them from disk.
